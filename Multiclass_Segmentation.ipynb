{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiclass_Segmentation.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCCKLgeVdbW3"
      },
      "source": [
        "\n",
        "# Get Dataset\n",
        "\n",
        "*  We get dataset from google drive that we will use. \n",
        "*  We combined all teams in a one directory divided training and test folders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N69FkIxJBMmG"
      },
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6HpQj3GBIVz"
      },
      "source": [
        "import os\n",
        "\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Set the seed for random operations. \n",
        "# This let our experiments to be reproducible. \n",
        "SEED = 1234\n",
        "tf.random.set_seed(SEED)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbnFFcMWOarR"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!unzip /content/drive/My\\ Drive/Development_Dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2EhRDwk1Xto"
      },
      "source": [
        "import shutil, random, json\n",
        "\n",
        "path = '/content/file'\n",
        "if not os.path.exists(path):       \n",
        "    if os.path.exists(path):\n",
        "        shutil.rmtree(path)\n",
        "    if not os.path.exists(path):\n",
        "        os.mkdir(path)\n",
        "    if not os.path.exists(path+'/training'):\n",
        "        os.mkdir(path+'/training')\n",
        "    if not os.path.exists(path+'/test'):\n",
        "        os.mkdir(path+'/test')\n",
        "\n",
        "    source_image = ['/content/Development_Dataset/Training/Bipbip/Haricot/Images','/content/Development_Dataset/Training/Bipbip/Mais/Images'\n",
        "                    ,'/content/Development_Dataset/Training/Pead/Haricot/Images','/content/Development_Dataset/Training/Pead/Mais/Images'\n",
        "                    ,'/content/Development_Dataset/Training/Roseau/Haricot/Images','/content/Development_Dataset/Training/Roseau/Mais/Images'\n",
        "                    ,'/content/Development_Dataset/Training/Weedelec/Haricot/Images','/content/Development_Dataset/Training/Weedelec/Mais/Images']\n",
        "\n",
        "    source_mask = ['/content/Development_Dataset/Training/Bipbip/Haricot/Masks','/content/Development_Dataset/Training/Bipbip/Mais/Masks'\n",
        "                    ,'/content/Development_Dataset/Training/Pead/Haricot/Masks','/content/Development_Dataset/Training/Pead/Mais/Masks'\n",
        "                    ,'/content/Development_Dataset/Training/Roseau/Haricot/Masks','/content/Development_Dataset/Training/Roseau/Mais/Masks'\n",
        "                    ,'/content/Development_Dataset/Training/Weedelec/Haricot/Masks','/content/Development_Dataset/Training/Weedelec/Mais/Masks']\n",
        "    \n",
        "    source_test = ['/content/Development_Dataset/Test_Dev/Bipbip/Haricot/Images','/content/Development_Dataset/Test_Dev/Bipbip/Mais/Images'\n",
        "                    ,'/content/Development_Dataset/Test_Dev/Pead/Haricot/Images','/content/Development_Dataset/Test_Dev/Pead/Mais/Images'\n",
        "                    ,'/content/Development_Dataset/Test_Dev/Roseau/Haricot/Images','/content/Development_Dataset/Test_Dev/Roseau/Mais/Images'\n",
        "                    ,'/content/Development_Dataset/Test_Dev/Weedelec/Haricot/Images','/content/Development_Dataset/Test_Dev/Weedelec/Mais/Images']\n",
        "\n",
        "    # Destination paths\n",
        "    dest_train = path+'/training'\n",
        "    dest_test = path+'/test'\n",
        "\n",
        "    if not os.path.exists(dest_train+'/'+'images'):\n",
        "        os.mkdir(dest_train+'/'+'images')\n",
        "    if not os.path.exists(dest_train+'/'+'masks'):\n",
        "        os.mkdir(dest_train+'/'+'masks')\n",
        "    if not os.path.exists(dest_test+'/'+'images'):\n",
        "        os.mkdir(dest_test+'/'+'images')\n",
        "    \n",
        "    for j in range(int(len(source_image))):\n",
        "      source_images = source_image[j]\n",
        "      source_masks = source_mask[j]\n",
        "      files = os.listdir(source_images)\n",
        "      m_files = os.listdir(source_masks)\n",
        "      random.shuffle(files)\n",
        "      #create training set randomly\n",
        "      for i in range(int(len(files))):\n",
        "          dest = shutil.copy(source_images+'/'+files[i], dest_train+'/images/'+files[i])\n",
        "          dest = shutil.copy(source_masks+'/'+m_files[i], dest_train+'/masks/'+m_files[i])\n",
        "\n",
        "    for j in range(int(len(source_test))):\n",
        "      source_img = source_test[j]\n",
        "      fil = os.listdir(source_img)\n",
        "      random.shuffle(fil)\n",
        "      #create training set randomly\n",
        "      for i in range(int(len(fil))):\n",
        "          dest = shutil.copy(source_img+'/'+fil[i], dest_test+'/images/'+fil[i])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_P31Ubv0nPH"
      },
      "source": [
        "input_dir = \"/content/file/training/images\"\n",
        "target_dir = \"/content/file/training/masks\"\n",
        "img_size = (256, 256)\n",
        "num_classes = 3\n",
        "batch_size = 2\n",
        "\n",
        "input_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(input_dir, fname)\n",
        "        for fname in os.listdir(input_dir)\n",
        "        if fname.endswith(\".jpg\")\n",
        "    ]\n",
        ")\n",
        "target_img_paths = sorted(\n",
        "    [\n",
        "        os.path.join(target_dir, fname)\n",
        "        for fname in os.listdir(target_dir)\n",
        "        if fname.endswith(\".png\") and not fname.startswith(\".\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"Number of samples:\", len(input_img_paths))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEOLf2pOdRMr"
      },
      "source": [
        "\n",
        "# Build Multi-class Image Segmentation\n",
        "\n",
        "*   We splits 0.25 of the training datas as validation datas.\n",
        "*   After,we defined train and valid generators and datasets.\n",
        "*   We defined image size as 256,256 and batch size as 32.\n",
        "*   We have 3 classes that are weed, crop and background.\n",
        "\n",
        "*   Then we create CustomDataset inheriting from tf.keras.utils.Sequence that returns a single sample from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8J23byCtDtC"
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "class CustomDataset(keras.utils.Sequence):\n",
        "\n",
        "    \"\"\" \n",
        "        CustomDataset inheriting from tf.keras.utils.Sequence. Helper to iterate over the data (as Numpy arrays).\n",
        "\n",
        "        3 main methods:\n",
        "          - __init__: save dataset params.\n",
        "          - __len__: return the total number of samples in the dataset into batches.\n",
        "          - __getitem__: return a sample from the dataset into batches.\n",
        "          \n",
        "        Note: \n",
        "          - the custom dataset return a single sample from the dataset. Then, we use \n",
        "            a tf.data.Dataset object to group samples.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, batch_size, img_size, input_img_paths, target_img_paths):\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.input_img_paths = input_img_paths\n",
        "        self.target_img_paths = target_img_paths\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.target_img_paths) // self.batch_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Returns tuple (input, target) correspond to batch #idx.\"\"\"\n",
        "        i = idx * self.batch_size\n",
        "        batch_input_img_paths = self.input_img_paths[i : i + self.batch_size]\n",
        "        batch_target_img_paths = self.target_img_paths[i : i + self.batch_size]\n",
        "        x = np.zeros((self.batch_size,) + self.img_size + (3,), dtype=\"float32\")\n",
        "        for j, path in enumerate(batch_input_img_paths):\n",
        "            img = load_img(path, target_size=self.img_size)\n",
        "            x[j] = img\n",
        "        y = np.zeros((self.batch_size,) + self.img_size + (1,), dtype=\"uint8\")\n",
        "        for j, path in enumerate(batch_target_img_paths):\n",
        "            img = load_img(path, target_size=self.img_size, color_mode=\"grayscale\")\n",
        "            y[j] = np.expand_dims(img, 2)\n",
        "        return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usz5SKPeQrOE"
      },
      "source": [
        "# Split our img paths into a training and a validation set\n",
        "val_samples = int((len(input_img_paths)*25)/100)\n",
        "train_input_img_paths = input_img_paths[:-val_samples]\n",
        "train_target_img_paths = target_img_paths[:-val_samples]\n",
        "val_input_img_paths = input_img_paths[-val_samples:]\n",
        "val_target_img_paths = target_img_paths[-val_samples:]\n",
        "\n",
        "# Instantiate data Sequences for each split\n",
        "train_gen = CustomDataset(batch_size, img_size, train_input_img_paths, train_target_img_paths)\n",
        "valid_gen = CustomDataset(batch_size, img_size, val_input_img_paths, val_target_img_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7xk3T5FeLL3"
      },
      "source": [
        "\n",
        "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([None,256, 256, 3], [None,256, 256, 1]))\n",
        "\n",
        "\n",
        "train_dataset = train_dataset.repeat()\n",
        "\n",
        "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen,\n",
        "                                               output_types=(tf.float32, tf.float32),\n",
        "                                               output_shapes=([None,256, 256, 3], [None,256, 256, 1]))\n",
        "\n",
        "valid_dataset = valid_dataset.repeat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjs-kiqCaKCf"
      },
      "source": [
        "# Let's test data generator\n",
        "# -------------------------\n",
        "import time\n",
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Assign a color to each class\n",
        "evenly_spaced_interval = np.linspace(0, 1, 20)\n",
        "colors = [cm.rainbow(x) for x in evenly_spaced_interval]\n",
        "\n",
        "iterator = iter(valid_dataset)\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "\n",
        "augmented_img, target = next(iterator)\n",
        "augmented_img = augmented_img[0]   # First element\n",
        "augmented_img = augmented_img  # denormalize\n",
        "\n",
        "target = np.array(target[0, ..., 0])   # First element (squeezing channel dimension)\n",
        "\n",
        "print(np.unique(target))\n",
        "\n",
        "target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
        "\n",
        "target_img[np.where(target == 0)] = [254, 124, 18]\n",
        "target_img[np.where(target == 1)] = [255, 255, 255]\n",
        "target_img[np.where(target == 2)] = [216, 67, 82]\n",
        "\n",
        "ax[0].imshow(np.uint8(augmented_img))\n",
        "ax[1].imshow(np.uint8(target_img))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "660pZzJmlsgz"
      },
      "source": [
        "# Prepare the model for training\n",
        "\n",
        "*   Here we decide to implement a transfer learning in a model that is VGG-19 which is recommended for segmentation problems. (Encoder-Decoder Network)\n",
        "*   SparseCategoricalCrossentropy defined for the loss to to use integers (mask) instead of one-hot encoded labels\n",
        "*   Adam optimizer with learning rate as 1e-4\n",
        "*   IoU metric\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eunbPwWqPnB"
      },
      "source": [
        "vgg = tf.keras.applications.VGG19(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "vgg.summary()\n",
        "for layer in vgg.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "def create_model(depth,num_classes):\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "    # Encoder\n",
        "    # -------\n",
        "    model.add(vgg)\n",
        "    \n",
        "    start_f = 256\n",
        "        \n",
        "    # Decoder\n",
        "    # -------\n",
        "    for i in range(depth):\n",
        "        model.add(tf.keras.layers.UpSampling2D(2, interpolation='bilinear'))\n",
        "        model.add(tf.keras.layers.Conv2D(filters=start_f,\n",
        "                                         kernel_size=(3, 3),\n",
        "                                         strides=(1, 1),\n",
        "                                         padding='same'))\n",
        "        model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "        start_f = start_f // 2\n",
        "\n",
        "    # Prediction Layer\n",
        "    # ----------------\n",
        "    model.add(tf.keras.layers.Conv2D(filters=num_classes,\n",
        "                                     kernel_size=(1, 1),\n",
        "                                     strides=(1, 1),\n",
        "                                     padding='same',\n",
        "                                     activation='softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "model = create_model(depth=5, \n",
        "                     num_classes=num_classes)\n",
        "\n",
        "# Free up RAM in case the model definition cells were run multiple times\n",
        "keras.backend.clear_session()\n",
        "\n",
        "# Visualize created model as a table\n",
        "model.summary()\n",
        "\n",
        "# Visualize initialized weights\n",
        "# model.weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfLR6kZJbYnH"
      },
      "source": [
        "# Optimization params\n",
        "# -------------------\n",
        "\n",
        "# Loss\n",
        "# Sparse Categorical Crossentropy to use integers (mask) instead of one-hot encoded labels\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy() \n",
        "# learning rate\n",
        "lr = 1e-3\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "# -------------------\n",
        "\n",
        "# Here we define the intersection over union for each class in the batch.\n",
        "# Then we compute the final iou as the mean over classes\n",
        "def meanIoU(y_true, y_pred):\n",
        "    # get predicted class from softmax\n",
        "    y_pred = tf.expand_dims(tf.argmax(y_pred, -1), -1)\n",
        "\n",
        "    per_class_iou = []\n",
        "\n",
        "    for i in range(1,3): # exclude the background class 0\n",
        "      # Get prediction and target related to only a single class (i)\n",
        "      class_pred = tf.cast(tf.where(y_pred == i, 1, 0), tf.float32)\n",
        "      class_true = tf.cast(tf.where(y_true == i, 1, 0), tf.float32)\n",
        "      intersection = tf.reduce_sum(class_true * class_pred)\n",
        "      union = tf.reduce_sum(class_true) + tf.reduce_sum(class_pred) - intersection\n",
        "    \n",
        "      iou = (intersection + 1e-7) / (union + 1e-7)\n",
        "      per_class_iou.append(iou)\n",
        "\n",
        "    return tf.reduce_mean(per_class_iou)\n",
        "\n",
        "# Validation metrics\n",
        "# ------------------\n",
        "metrics = ['accuracy', meanIoU]\n",
        "# ------------------\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUPbTmDBeADw"
      },
      "source": [
        "\n",
        "# Training with callbacks\n",
        "To have better scores we saved the weights, and re-train the model using the old weights. The result has been obtained in this way:\n",
        "\n",
        "*   Early Stopping,Model checkpoint and Tensorboard were declared as callbacks\n",
        "*   Training the model 50 times.\n",
        "*   We reach a plateau. The validation score was stable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pmX9MdVD0wI"
      },
      "source": [
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "cwd = os.getcwd()\n",
        "\n",
        "exps_dir = os.path.join(cwd, 'drive/My Drive/Keras4/', 'multiclass_segmentation_experiments')\n",
        "if not os.path.exists(exps_dir):\n",
        "    os.makedirs(exps_dir)\n",
        "\n",
        "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
        "\n",
        "model_name = 'CNN'\n",
        "\n",
        "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
        "if not os.path.exists(exp_dir):\n",
        "    os.makedirs(exp_dir)\n",
        "    \n",
        "callbacks = []\n",
        "\n",
        "# Model checkpoint\n",
        "# ----------------\n",
        "ckpt_dir = os.path.join(exp_dir, 'ckpts')\n",
        "if not os.path.exists(ckpt_dir):\n",
        "    os.makedirs(ckpt_dir)\n",
        "\n",
        "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(ckpt_dir, 'cp_{epoch:02d}.ckpt'), \n",
        "                                                   save_weights_only=True)  # False to save the model directly\n",
        "callbacks.append(ckpt_callback)\n",
        "\n",
        "# Visualize Learning on Tensorboard\n",
        "# ---------------------------------\n",
        "tb_dir = os.path.join(exp_dir, 'tb_logs')\n",
        "if not os.path.exists(tb_dir):\n",
        "    os.makedirs(tb_dir)\n",
        "    \n",
        "# By default shows losses and metrics for both training and validation\n",
        "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=tb_dir,\n",
        "                                             profile_batch=0,\n",
        "                                             histogram_freq=0)  # if 1 shows weights histograms\n",
        "callbacks.append(tb_callback)\n",
        "\n",
        "# Early Stopping\n",
        "# --------------\n",
        "early_stop = False\n",
        "if early_stop:\n",
        "    es_callback = tf.keras.callback.EarlyStopping(monitor='val_loss', patience=10)\n",
        "    callbacks.append(es_callback)\n",
        "\n",
        "model.fit(x=train_dataset,\n",
        "          epochs=50,  #### set repeat in training dataset\n",
        "          steps_per_epoch=len(train_gen),\n",
        "          validation_data=valid_dataset,\n",
        "          validation_steps=len(valid_gen), \n",
        "          callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX4yOYbXdpgV"
      },
      "source": [
        "\n",
        "# Prepare Test to Prediction\n",
        "\n",
        "*   Firstly, We test model using valid_dataset looking real, target and prediction images.\n",
        "*   Then, we test model using test images same as before. We created json data and filled our predictions.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acgUXQhbwyCA"
      },
      "source": [
        "from PIL import Image, ImageOps\n",
        "\n",
        "# Generate predictions for all images in the validation set\n",
        "val_gen = CustomDataset(batch_size, img_size, val_input_img_paths, val_target_img_paths)\n",
        "val_preds = model.predict(val_gen)\n",
        "\n",
        "\n",
        "def display_mask(i):\n",
        "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
        "    mask = np.argmax(val_preds[i], axis=-1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    img = ImageOps.autocontrast(tf.keras.preprocessing.image.array_to_img(mask))\n",
        "    display(img)\n",
        "\n",
        "\n",
        "# Display results for validation image #10\n",
        "i = 10\n",
        "\n",
        "# Display ground-truth target mask\n",
        "img = ImageOps.autocontrast(load_img(val_target_img_paths[i]))\n",
        "display(img)\n",
        "\n",
        "# Display mask predicted by our model\n",
        "display_mask(i)  # Note that the model only sees inputs at 150x150."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LwVQckL0f1j"
      },
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "import time\n",
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# Assign a color to each class\n",
        "evenly_spaced_interval = np.linspace(0, 1, 20)\n",
        "colors = [cm.rainbow(x) for x in evenly_spaced_interval]\n",
        "\n",
        "iterator = iter(valid_dataset)\n",
        "fig, ax = plt.subplots(1, 3, figsize=(8, 8))\n",
        "fig.show()\n",
        "image, target = next(iterator)\n",
        "\n",
        "image = image[0]\n",
        "target = target[0, ..., 0]\n",
        "\n",
        "out_sigmoid = model.predict(x=tf.expand_dims(image, 0))\n",
        "\n",
        "# Get predicted class as the index corresponding to the maximum value in the vector probability\n",
        "# predicted_class = tf.cast(out_sigmoid > score_th, tf.int32)\n",
        "# predicted_class = predicted_class[0, ..., 0]\n",
        "predicted_class = tf.argmax(out_sigmoid, -1)\n",
        "\n",
        "out_sigmoid.shape\n",
        "\n",
        "predicted_class = predicted_class[0, ...]\n",
        "\n",
        "# Assign colors (just for visualization)\n",
        "target_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
        "prediction_img = np.zeros([target.shape[0], target.shape[1], 3])\n",
        "\n",
        "target_img[np.where(target == 0)] = [254 ,124 ,18]\n",
        "target_img[np.where(target == 1)] = [255, 255, 255]\n",
        "target_img[np.where(target == 2)] = [216, 67, 82]\n",
        "\n",
        "\n",
        "prediction_img[np.where(predicted_class == 0)] = [254 ,124 ,18]\n",
        "prediction_img[np.where(predicted_class == 1)] = [255, 255, 255]\n",
        "prediction_img[np.where(predicted_class == 2)] = [216, 67, 82]\n",
        "\n",
        "ax[0].imshow(np.uint8(image))\n",
        "ax[1].imshow(np.uint8(target_img))\n",
        "ax[2].imshow(np.uint8(prediction_img))\n",
        "\n",
        "fig.canvas.draw()\n",
        "time.sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JrbagaZfoFI"
      },
      "source": [
        "# Cycle over test images    \n",
        "test_dir = \"/content/file/test\"\n",
        "test_img_dir = os.path.join(test_dir, 'images')\n",
        "\n",
        "img_filenames = os.listdir(test_img_dir)\n",
        "\n",
        "\n",
        "def rle_encode(img):\n",
        "    pixels = img.flatten()\n",
        "    pixels = np.concatenate([[0], pixels, [0]])\n",
        "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
        "    runs[1::2] -= runs[::2]\n",
        "    return ' '.join(str(x) for x in runs)   \n",
        "\n",
        "evenly_spaced_interval = np.linspace(0, 1, 20)\n",
        "colors = [cm.rainbow(x) for x in evenly_spaced_interval]\n",
        "\n",
        "# Finally, save the results into the submission.json file\n",
        "with open('/content/file/submission.json', 'w') as f:\n",
        "  for img_filename in img_filenames:\n",
        "      img_name = img_filename\n",
        "      img = Image.open(os.path.join(test_img_dir,img_name))\n",
        "      img = img.resize((256, 256))\n",
        "      img_arr = np.expand_dims(np.array(img), 0)\n",
        "\n",
        "      out_sigmoid = model.predict(x=img_arr / 1.)\n",
        "\n",
        "      # Get predicted class as the index corresponding to the maximum value in the vector probability\n",
        "      # predicted_class = tf.cast(out_sigmoid > score_th, tf.int32)\n",
        "      # predicted_class = predicted_class[0, ..., 0]\n",
        "      predicted_class = tf.argmax(out_sigmoid, -1)\n",
        "\n",
        "      predicted_class = predicted_class[0, ...]\n",
        "      prediction_img[np.where(predicted_class == 0)] = [254 ,124 ,18]\n",
        "      prediction_img[np.where(predicted_class == 1)] = [255, 255, 255]\n",
        "      prediction_img[np.where(predicted_class == 2)] = [216, 67, 82]\n",
        "        \n",
        "\n",
        "      t=img_name.split('_')\n",
        "\n",
        "      submission_dict = {}\n",
        "      submission_dict[img_name] = {}\n",
        "      submission_dict[img_name]['shape'] = '[256,256]'\n",
        "      submission_dict[img_name]['team'] = t[0]\n",
        "      submission_dict[img_name]['crop'] = t[1]\n",
        "      submission_dict[img_name]['segmentation'] = {}\n",
        "\n",
        "      # crop\n",
        "      rle_encoded_crop = rle_encode( np.uint8(prediction_img[np.where(predicted_class == 1)]/255) )\n",
        "      # weed\n",
        "      rle_encoded_weed = rle_encode( np.uint8(prediction_img[np.where(predicted_class == 2)]/255) )\n",
        "\n",
        "      submission_dict[img_name]['segmentation']['crop'] = rle_encoded_crop\n",
        "      submission_dict[img_name]['segmentation']['weed'] = rle_encoded_weed\n",
        "      json.dump(submission_dict, f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}